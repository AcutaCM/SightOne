# VLM API 404 éŒ¯èª¤ä¿®å¾©å ±å‘Š

## ğŸ› å•é¡Œæè¿°

**éŒ¯èª¤ä¿¡æ¯**:
```
æœå‹™èª¿ç”¨å¤±æ•—ï¼ˆ404ï¼‰ï¼š{"error":"Upstream error: 404"}
é…ç½®å¥½é›²ç«¯å¾Œä»ç„¡æ³•èª¿ç”¨ VLM æ¨¡å‹
```

## ğŸ” æ ¹æœ¬åŸå› 

Python å¾Œç«¯ (`crop_diagnosis_workflow.py`) ç™¼é€çš„è«‹æ±‚æ ¼å¼èˆ‡ Next.js `chat-proxy` API ä¸å…¼å®¹ï¼š

### å•é¡Œ 1: Messages æ ¼å¼éŒ¯èª¤
**éŒ¯èª¤çš„æ ¼å¼** (OpenAI åŸç”Ÿæ ¼å¼):
```python
{
    "messages": [
        {
            "role": "user",
            "content": [  # âŒ æ•¸çµ„æ ¼å¼
                {"type": "text", "text": "..."},
                {"type": "image_url", "image_url": {...}}
            ]
        }
    ]
}
```

`chat-proxy` æœŸæœ›çš„æ˜¯ **Markdown æ ¼å¼**çš„åœ–ç‰‡åµŒå…¥ï¼Œè€Œä¸æ˜¯ OpenAI çš„å¤šæ¨¡æ…‹æ•¸çµ„æ ¼å¼ã€‚

### å•é¡Œ 2: ä¸æ”¯æŒçš„åƒæ•¸
- `response_format` åƒæ•¸åœ¨ `chat-proxy` ä¸­ä¸å­˜åœ¨
- åƒæ•¸åç¨±ä¸åŒ¹é…ï¼š`max_tokens` vs `maxTokens`

## âœ… ä¿®å¾©æ–¹æ¡ˆ

### 1. æ›´æ–° `_call_vlm_api` æ–¹æ³•

**æ–‡ä»¶**: `drone-analyzer-nextjs/python/crop_diagnosis_workflow.py`

**ä¿®æ”¹å…§å®¹**:

```python
async def _call_vlm_api(self, image_base64: str, plant_id: int) -> Optional[Dict]:
    # æ§‹å»º Markdown æ ¼å¼çš„åœ–ç‰‡åµŒå…¥
    image_data_url = f"data:image/jpeg;base64,{image_base64}"
    content_with_image = f"{prompt}\n\n![æ¤æ ªå›¾åƒ]({image_data_url})"
    
    # ç¬¦åˆ chat-proxy API æ ¼å¼çš„è«‹æ±‚
    request_data = {
        "provider": self.ai_config.get("provider", "openai"),
        "model": self.ai_config.get("model", "gpt-4-vision-preview"),
        "messages": [
            {
                "role": "user",
                "content": content_with_image  # âœ… å­—ç¬¦ä¸²æ ¼å¼ï¼ŒåŒ…å« Markdown åœ–ç‰‡
            }
        ],
        "temperature": self.ai_config.get("temperature", 0.7),
        "maxTokens": self.ai_config.get("maxTokens", self.ai_config.get("max_tokens", 2048)),
        "apiKey": self.ai_config.get("apiKey", self.ai_config.get("api_key", "")),
        "baseUrl": self.ai_config.get("baseUrl", self.ai_config.get("base_url", ""))
    }
    
    # ç§»é™¤ç©ºå€¼
    request_data = {k: v for k, v in request_data.items() if v}
    
    # ç™¼é€è«‹æ±‚ä¸¦è™•ç†éŸ¿æ‡‰
    async with httpx.AsyncClient(timeout=60.0) as client:
        response = await client.post(self.chat_proxy_url, json=request_data)
        
        if response.status_code != 200:
            print(f"âŒ API éŒ¯èª¤ ({response.status_code}): {response.text}")
            return None
        
        result = response.json()
        content = result.get('content', '')  # âœ… chat-proxy è¿”å›æ ¼å¼
        
        # è§£æ JSON
        return json.loads(content)
```

### 2. åƒæ•¸åç¨±æ˜ å°„

æ”¯æŒå…©ç¨®å‘½åé¢¨æ ¼ï¼š

| Python é¢¨æ ¼ | JavaScript é¢¨æ ¼ |
|------------|----------------|
| `api_key`  | `apiKey`       |
| `base_url` | `baseUrl`      |
| `max_tokens` | `maxTokens`  |

### 3. æ·»åŠ èª¿è©¦æ—¥èªŒ

```python
print(f"ğŸ” ç™¼é€è¨ºæ–·è«‹æ±‚: provider={request_data.get('provider')}, model={request_data.get('model')}")
print(f"ğŸ“¡ éŸ¿æ‡‰ç‹€æ…‹ç¢¼: {response.status_code}")
```

## ğŸ“ ä½¿ç”¨èªªæ˜

### 1. é…ç½® AI æ¨¡å‹

```python
workflow.set_ai_config({
    "provider": "openai",  # æˆ– anthropic, gemini, qwen ç­‰
    "model": "gpt-4-vision-preview",
    "apiKey": "sk-...",  # æˆ–ä½¿ç”¨ api_key
    "temperature": 0.7,
    "maxTokens": 2048
})
```

### 2. æ¸¬è©¦é…ç½®

é‹è¡Œæ¸¬è©¦è…³æœ¬ï¼š
```bash
python test_vlm_config.py openai gpt-4-vision-preview sk-your-api-key
```

### 3. æŸ¥çœ‹æ—¥èªŒ

æ­£å¸¸è¼¸å‡ºï¼š
```
ğŸ” ç™¼é€è¨ºæ–·è«‹æ±‚: provider=openai, model=gpt-4-vision-preview
ğŸ“¡ éŸ¿æ‡‰ç‹€æ…‹ç¢¼: 200
âœ… è¨ºæ–·å®Œæˆ: æ¤æ ª 1
```

éŒ¯èª¤è¼¸å‡ºï¼š
```
ğŸ” ç™¼é€è¨ºæ–·è«‹æ±‚: provider=openai, model=gpt-4-vision-preview
ğŸ“¡ éŸ¿æ‡‰ç‹€æ…‹ç¢¼: 404
âŒ API éŒ¯èª¤ (404): {"error":"Upstream error: 404"}
```

## ğŸ¯ æ”¯æŒçš„ AI æä¾›å•†

### OpenAI
```python
{
    "provider": "openai",
    "model": "gpt-4-vision-preview",
    "apiKey": "sk-..."
}
```

### Anthropic (Claude)
```python
{
    "provider": "anthropic",
    "model": "claude-3-opus-20240229",
    "apiKey": "sk-ant-..."
}
```

### Google Gemini
```python
{
    "provider": "gemini",
    "model": "gemini-pro-vision",
    "apiKey": "AIza..."
}
```

### é˜¿é‡Œé€šç¾©åƒå• (Qwen VL)
```python
{
    "provider": "qwen",
    "model": "qwen-vl-plus",
    "apiKey": "sk-...",
    "baseUrl": "https://dashscope.aliyuncs.com/compatible-mode/v1"
}
```

## ğŸ“¦ ä¿®æ”¹çš„æ–‡ä»¶

### 1. Python å¾Œç«¯
- âœ… `drone-analyzer-nextjs/python/crop_diagnosis_workflow.py`
  - ä¿®å¾© `_call_vlm_api` æ–¹æ³•
  - ä½¿ç”¨ Markdown æ ¼å¼åœ–ç‰‡åµŒå…¥
  - ç§»é™¤ä¸æ”¯æŒçš„åƒæ•¸
  - æ·»åŠ èª¿è©¦æ—¥èªŒ

### 2. æ¸¬è©¦å·¥å…·
- âœ… `drone-analyzer-nextjs/test_vlm_config.py` - VLM é…ç½®æ¸¬è©¦è…³æœ¬

### 3. æ–‡æª”
- âœ… `drone-analyzer-nextjs/docs/VLM_CONFIGURATION_GUIDE.md` - å®Œæ•´é…ç½®æŒ‡å—
- âœ… `drone-analyzer-nextjs/VLM_API_FIX.md` - æœ¬ä¿®å¾©å ±å‘Š

## ğŸ”§ æ•…éšœæ’é™¤

### éŒ¯èª¤ 1: 404 Upstream error
**åŸå› **: æ¨¡å‹åç¨±éŒ¯èª¤æˆ–ç«¯é»ä¸å­˜åœ¨

**è§£æ±º**:
- æª¢æŸ¥æ¨¡å‹åç¨±æ‹¼å¯«
- ç¢ºèªæ¨¡å‹æ”¯æŒåœ–åƒè¼¸å…¥
- é©—è­‰ API ç«¯é»

### éŒ¯èª¤ 2: 401 Unauthorized
**åŸå› **: API å¯†é‘°ç„¡æ•ˆ

**è§£æ±º**:
- é‡æ–°ç”Ÿæˆ API å¯†é‘°
- æª¢æŸ¥é…é¡æ˜¯å¦å……è¶³

### éŒ¯èª¤ 3: é€£æ¥éŒ¯èª¤
**åŸå› **: Next.js æ‡‰ç”¨æœªé‹è¡Œ

**è§£æ±º**:
```bash
cd drone-analyzer-nextjs
npm run dev
```

## ğŸ“š ç›¸é—œæ–‡æª”

- [VLM é…ç½®æŒ‡å—](./docs/VLM_CONFIGURATION_GUIDE.md)
- [è¨ºæ–·å·¥ä½œæµæ–‡æª”](./docs/DIAGNOSIS_WORKFLOW_WITH_SEGMENTATION.md)
- [chat-proxy API æºç¢¼](./app/api/chat-proxy/route.ts)

## âœ… é©—è­‰æ­¥é©Ÿ

1. **æ¸¬è©¦ chat-proxy API**
   ```bash
   python test_vlm_config.py openai gpt-4-vision-preview YOUR_API_KEY
   ```

2. **é‹è¡Œè¨ºæ–·å·¥ä½œæµ**
   ```python
   workflow = CropDiagnosisWorkflow()
   workflow.set_ai_config({
       "provider": "openai",
       "model": "gpt-4-vision-preview",
       "apiKey": "sk-..."
   })
   ```

3. **æŸ¥çœ‹æ—¥èªŒè¼¸å‡º**
   - ç¢ºèªç‹€æ…‹ç¢¼ç‚º 200
   - é©—è­‰è¿”å›å…§å®¹æ­£ç¢º

---

**ä¿®å¾©ç‹€æ…‹**: âœ… å·²å®Œæˆ  
**æ¸¬è©¦ç‹€æ…‹**: å¾…ç”¨æˆ¶é©—è­‰  
**æ–‡æª”ç‹€æ…‹**: âœ… å·²å®Œå–„

