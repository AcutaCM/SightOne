#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
AIé…ç½®ç®¡ç†å™¨
è´Ÿè´£ç®¡ç†AIæ¨¡å‹é…ç½®ã€éªŒè¯è§†è§‰æ”¯æŒèƒ½åŠ›ã€åˆ›å»ºAIå®¢æˆ·ç«¯
"""

import os
from dataclasses import dataclass
from typing import Optional, Dict, Any
import logging

# å¯¼å…¥é”™è¯¯å¤„ç†æ¨¡å—
try:
    from ai_config_errors import AIConfigErrorHandler, AIConfigError, AIConfigErrorType
    ERROR_HANDLER_AVAILABLE = True
except ImportError:
    ERROR_HANDLER_AVAILABLE = False
    logger.warning("âš ï¸ AIé…ç½®é”™è¯¯å¤„ç†æ¨¡å—ä¸å¯ç”¨")

logger = logging.getLogger(__name__)


@dataclass
class AIConfig:
    """AIé…ç½®æ•°æ®ç±»"""
    provider: str  # openai, anthropic, google, etc.
    model: str
    api_key: str
    api_base: str
    supports_vision: bool
    max_tokens: int = 2000
    temperature: float = 0.7
    
    # äº‘ç«¯æç¤ºè¯æœåŠ¡é…ç½®
    cloud_prompt_service: Optional[str] = None
    cloud_api_key: Optional[str] = None


class AIConfigManager:
    """AIé…ç½®ç®¡ç†å™¨"""
    
    # æ”¯æŒè§†è§‰çš„æ¨¡å‹åˆ—è¡¨
    VISION_MODELS = {
        'openai': [
            'gpt-4-vision-preview',
            'gpt-4-turbo',
            'gpt-4o',
            'gpt-4o-mini'
        ],
        'anthropic': [
            'claude-3-opus',
            'claude-3-sonnet',
            'claude-3-haiku',
            'claude-3-5-sonnet'
        ],
        'google': [
            'gemini-pro-vision',
            'gemini-1.5-pro',
            'gemini-1.5-flash'
        ],
        'qwen': [
            'qwen-vl-plus',
            'qwen-vl-max',
            'qwen-vl-chat',
            'qwen2-vl-7b-instruct',
            'qwen2-vl-72b-instruct',
            'qwen2-vl-2b-instruct',
            'qwen3-vl',
            'qwen3-vl-plus',
            'qwen3-vl-max'
        ],
        'dashscope': [
            'qwen-vl-plus',
            'qwen-vl-max',
            'qwen-vl-chat',
            'qwen2-vl-7b-instruct',
            'qwen2-vl-72b-instruct',
            'qwen2-vl-2b-instruct',
            'qwen3-vl',
            'qwen3-vl-plus',
            'qwen3-vl-max'
        ]
    }
    
    # é»˜è®¤APIç«¯ç‚¹
    DEFAULT_API_BASES = {
        'openai': 'https://api.openai.com/v1',
        'anthropic': 'https://api.anthropic.com',
        'google': 'https://generativelanguage.googleapis.com',
        'qwen': 'https://dashscope.aliyuncs.com/compatible-mode/v1',
        'dashscope': 'https://dashscope.aliyuncs.com/api/v1'
    }
    
    def __init__(self):
        """åˆå§‹åŒ–AIé…ç½®ç®¡ç†å™¨"""
        self.config: Optional[AIConfig] = None
        self._load_env_config()
    
    def _load_env_config(self):
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é»˜è®¤é…ç½®ï¼ˆä½œä¸ºåå¤‡ï¼‰"""
        provider = os.getenv('DEFAULT_AI_PROVIDER')
        model = os.getenv('DEFAULT_AI_MODEL')
        
        if provider and model:
            api_key = os.getenv(f'{provider.upper()}_API_KEY')
            api_base = os.getenv(f'{provider.upper()}_API_BASE')
            
            if api_key:
                logger.info(f"ä»ç¯å¢ƒå˜é‡åŠ è½½é»˜è®¤AIé…ç½®: {provider}/{model}")
                self.config = AIConfig(
                    provider=provider,
                    model=model,
                    api_key=api_key,
                    api_base=api_base or self.DEFAULT_API_BASES.get(provider, ''),
                    supports_vision=self._check_vision_support(provider, model)
                )

    
    def load_config_from_frontend(self, config_data: Dict[str, Any]) -> AIConfig:
        """
        ä»å‰ç«¯ä¼ é€’çš„é…ç½®åŠ è½½AIé…ç½®
        
        Args:
            config_data: å‰ç«¯ä¼ é€’çš„é…ç½®å­—å…¸ï¼ŒåŒ…å«:
                - provider: AIæä¾›å•† (openai, anthropic, google)
                - model: æ¨¡å‹åç§°
                - api_key: APIå¯†é’¥
                - api_base: APIç«¯ç‚¹ (å¯é€‰)
                - max_tokens: æœ€å¤§tokenæ•° (å¯é€‰)
                - temperature: æ¸©åº¦å‚æ•° (å¯é€‰)
                - cloud_prompt_service: äº‘ç«¯æç¤ºè¯æœåŠ¡URL (å¯é€‰)
                - cloud_api_key: äº‘ç«¯æœåŠ¡APIå¯†é’¥ (å¯é€‰)
        
        Returns:
            AIConfigå¯¹è±¡
        
        Raises:
            ValueError: é…ç½®æ— æ•ˆæ—¶æŠ›å‡º
        """
        # ä½¿ç”¨é”™è¯¯å¤„ç†å™¨éªŒè¯é…ç½®
        if ERROR_HANDLER_AVAILABLE:
            validation_error = AIConfigErrorHandler.validate_config(config_data)
            if validation_error:
                logger.error(f"âŒ é…ç½®éªŒè¯å¤±è´¥: {validation_error.message}")
                # è®°å½•æ¢å¤å»ºè®®
                for suggestion in validation_error.recovery_suggestions:
                    logger.info(f"ğŸ’¡ å»ºè®®: {suggestion}")
                raise ValueError(validation_error.message)
        else:
            # å›é€€åˆ°åŸºæœ¬éªŒè¯
            required_fields = ['provider', 'model', 'api_key']
            for field in required_fields:
                if field not in config_data:
                    raise ValueError(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
        
        provider = config_data['provider'].lower()
        model = config_data['model']
        api_key = config_data['api_key']
        
        # éªŒè¯æä¾›å•†
        if provider not in self.VISION_MODELS:
            raise ValueError(f"ä¸æ”¯æŒçš„AIæä¾›å•†: {provider}")
        
        # æ£€æŸ¥åº“å¯ç”¨æ€§
        if ERROR_HANDLER_AVAILABLE:
            library_error = AIConfigErrorHandler.check_library_availability(provider)
            if library_error:
                logger.error(f"âŒ åº“æ£€æŸ¥å¤±è´¥: {library_error.message}")
                for suggestion in library_error.recovery_suggestions:
                    logger.info(f"ğŸ’¡ å»ºè®®: {suggestion}")
                raise ImportError(library_error.message)
        
        # è·å–æˆ–ä½¿ç”¨é»˜è®¤APIç«¯ç‚¹
        api_base = config_data.get('api_base') or self.DEFAULT_API_BASES.get(provider, '')
        
        # æ£€æŸ¥è§†è§‰æ”¯æŒ
        supports_vision = self._check_vision_support(provider, model)
        
        # åˆ›å»ºé…ç½®å¯¹è±¡
        self.config = AIConfig(
            provider=provider,
            model=model,
            api_key=api_key,
            api_base=api_base,
            supports_vision=supports_vision,
            max_tokens=config_data.get('max_tokens', 2000),
            temperature=config_data.get('temperature', 0.7),
            cloud_prompt_service=config_data.get('cloud_prompt_service'),
            cloud_api_key=config_data.get('cloud_api_key')
        )
        
        logger.info(f"âœ… åŠ è½½AIé…ç½®: {provider}/{model}, è§†è§‰æ”¯æŒ: {supports_vision}")
        
        return self.config
    
    def _check_vision_support(self, provider: str, model: str) -> bool:
        """
        æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒè§†è§‰åŠŸèƒ½
        
        Args:
            provider: AIæä¾›å•†
            model: æ¨¡å‹åç§°
        
        Returns:
            æ˜¯å¦æ”¯æŒè§†è§‰
        """
        if provider not in self.VISION_MODELS:
            return False
        
        # è½¬æ¢ä¸ºå°å†™è¿›è¡Œæ¯”è¾ƒ
        model_lower = model.lower()
        
        # æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦åœ¨æ”¯æŒåˆ—è¡¨ä¸­
        supported_models = self.VISION_MODELS[provider]
        
        # ç²¾ç¡®åŒ¹é…
        if model in supported_models:
            return True
        
        # æ¨¡ç³ŠåŒ¹é…ï¼ˆå¤„ç†ç‰ˆæœ¬å·ç­‰ï¼‰
        for supported_model in supported_models:
            if supported_model in model or model in supported_model:
                return True
        
        # æ™ºèƒ½æ£€æµ‹ï¼šæ£€æŸ¥æ¨¡å‹åç§°ä¸­æ˜¯å¦åŒ…å«è§†è§‰ç›¸å…³å…³é”®è¯
        vision_keywords = [
            'vision', 'vl', 'visual', 'multimodal', 
            'image', 'video', 'see', 'view'
        ]
        
        # å¯¹äºqwen/dashscopeæä¾›å•†ï¼Œç‰¹åˆ«æ£€æŸ¥vlå…³é”®è¯
        if provider in ['qwen', 'dashscope']:
            # qwen-vl, qwen2-vl, qwen3-vl ç­‰éƒ½åº”è¯¥è¢«è¯†åˆ«
            if 'vl' in model_lower or 'vision' in model_lower:
                logger.info(f"âœ… é€šè¿‡å…³é”®è¯æ£€æµ‹è¯†åˆ«è§†è§‰æ¨¡å‹: {model}")
                return True
        
        # å¯¹äºå…¶ä»–æä¾›å•†ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«visionå…³é”®è¯
        for keyword in vision_keywords:
            if keyword in model_lower:
                logger.info(f"âœ… é€šè¿‡å…³é”®è¯æ£€æµ‹è¯†åˆ«è§†è§‰æ¨¡å‹: {model} (å…³é”®è¯: {keyword})")
                return True
        
        # å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œè®°å½•è­¦å‘Šä½†ä¸ç›´æ¥æ‹’ç»
        logger.warning(f"âš ï¸ æ¨¡å‹ {model} æœªåœ¨å·²çŸ¥è§†è§‰æ¨¡å‹åˆ—è¡¨ä¸­ï¼Œä½†å¯èƒ½æ”¯æŒè§†è§‰åŠŸèƒ½")
        logger.warning(f"   å¦‚æœè¯¥æ¨¡å‹ç¡®å®æ”¯æŒè§†è§‰ï¼Œè¯·å°†å…¶æ·»åŠ åˆ° VISION_MODELS åˆ—è¡¨ä¸­")
        
        return False
    
    def validate_vision_support(self) -> bool:
        """
        éªŒè¯å½“å‰é…ç½®çš„æ¨¡å‹æ˜¯å¦æ”¯æŒè§†è§‰åŠŸèƒ½
        
        Returns:
            æ˜¯å¦æ”¯æŒè§†è§‰
        
        Raises:
            RuntimeError: æœªé…ç½®AIæ¨¡å‹æ—¶æŠ›å‡º
        """
        if not self.config:
            raise RuntimeError("æœªé…ç½®AIæ¨¡å‹")
        
        if not self.config.supports_vision:
            logger.error(f"âŒ æ¨¡å‹ {self.config.model} ä¸æ”¯æŒè§†è§‰åŠŸèƒ½")
            return False
        
        logger.info(f"âœ… æ¨¡å‹ {self.config.model} æ”¯æŒè§†è§‰åŠŸèƒ½")
        return True

    
    def get_client(self):
        """
        è·å–é…ç½®å¥½çš„AIå®¢æˆ·ç«¯
        
        Returns:
            AIå®¢æˆ·ç«¯å®ä¾‹
        
        Raises:
            RuntimeError: æœªé…ç½®AIæ¨¡å‹æ—¶æŠ›å‡º
            ImportError: ç¼ºå°‘å¿…éœ€çš„åº“æ—¶æŠ›å‡º
        """
        if not self.config:
            raise RuntimeError("æœªé…ç½®AIæ¨¡å‹ï¼Œè¯·å…ˆè°ƒç”¨ load_config_from_frontend()")
        
        provider = self.config.provider
        
        if provider == 'openai':
            return self._create_openai_client()
        elif provider == 'anthropic':
            return self._create_anthropic_client()
        elif provider == 'google':
            return self._create_google_client()
        elif provider in ['qwen', 'dashscope']:
            # åƒé—®å¯ä»¥ä½¿ç”¨OpenAIå…¼å®¹æ¥å£æˆ–DashScope SDK
            if provider == 'qwen':
                return self._create_qwen_client()
            else:
                return self._create_dashscope_client()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„AIæä¾›å•†: {provider}")
    
    def _create_openai_client(self):
        """åˆ›å»ºOpenAIå®¢æˆ·ç«¯"""
        try:
            from openai import AsyncOpenAI
        except ImportError:
            raise ImportError("è¯·å®‰è£… openai åº“: pip install openai")
        
        client = AsyncOpenAI(
            api_key=self.config.api_key,
            base_url=self.config.api_base
        )
        
        logger.info(f"âœ… åˆ›å»ºOpenAIå®¢æˆ·ç«¯: {self.config.model}")
        return client
    
    def _create_anthropic_client(self):
        """åˆ›å»ºAnthropicå®¢æˆ·ç«¯"""
        try:
            from anthropic import AsyncAnthropic
        except ImportError:
            raise ImportError("è¯·å®‰è£… anthropic åº“: pip install anthropic")
        
        client = AsyncAnthropic(
            api_key=self.config.api_key,
            base_url=self.config.api_base if self.config.api_base else None
        )
        
        logger.info(f"âœ… åˆ›å»ºAnthropicå®¢æˆ·ç«¯: {self.config.model}")
        return client
    
    def _create_google_client(self):
        """åˆ›å»ºGoogleå®¢æˆ·ç«¯"""
        try:
            import google.generativeai as genai
        except ImportError:
            raise ImportError("è¯·å®‰è£… google-generativeai åº“: pip install google-generativeai")
        
        genai.configure(api_key=self.config.api_key)
        
        logger.info(f"âœ… åˆ›å»ºGoogleå®¢æˆ·ç«¯: {self.config.model}")
        return genai
    
    def _create_qwen_client(self):
        """åˆ›å»ºåƒé—®å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨OpenAIå…¼å®¹æ¥å£ï¼‰"""
        try:
            from openai import AsyncOpenAI
        except ImportError:
            raise ImportError("è¯·å®‰è£… openai åº“: pip install openai")
        
        # åƒé—®ä½¿ç”¨OpenAIå…¼å®¹çš„APIæ¥å£
        client = AsyncOpenAI(
            api_key=self.config.api_key,
            base_url=self.config.api_base or self.DEFAULT_API_BASES['qwen']
        )
        
        logger.info(f"âœ… åˆ›å»ºåƒé—®å®¢æˆ·ç«¯: {self.config.model}")
        return client
    
    def _create_dashscope_client(self):
        """åˆ›å»ºDashScopeå®¢æˆ·ç«¯ï¼ˆé˜¿é‡Œäº‘çµç§¯ï¼‰"""
        try:
            import dashscope
        except ImportError:
            raise ImportError("è¯·å®‰è£… dashscope åº“: pip install dashscope")
        
        # é…ç½®DashScope APIå¯†é’¥
        dashscope.api_key = self.config.api_key
        
        logger.info(f"âœ… åˆ›å»ºDashScopeå®¢æˆ·ç«¯: {self.config.model}")
        return dashscope
    
    def get_config(self) -> Optional[AIConfig]:
        """
        è·å–å½“å‰é…ç½®
        
        Returns:
            å½“å‰AIé…ç½®ï¼Œå¦‚æœæœªé…ç½®åˆ™è¿”å›None
        """
        return self.config
    
    def is_configured(self) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦å·²é…ç½®AIæ¨¡å‹
        
        Returns:
            æ˜¯å¦å·²é…ç½®
        """
        return self.config is not None
    
    def clear_config(self):
        """æ¸…é™¤å½“å‰é…ç½®"""
        self.config = None
        logger.info("ğŸ§¹ æ¸…é™¤AIé…ç½®")
    
    def get_supported_models(self, provider: str) -> list:
        """
        è·å–æŒ‡å®šæä¾›å•†æ”¯æŒçš„è§†è§‰æ¨¡å‹åˆ—è¡¨
        
        Args:
            provider: AIæä¾›å•†
        
        Returns:
            æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
        """
        return self.VISION_MODELS.get(provider.lower(), [])
    
    def get_supported_providers(self) -> list:
        """
        è·å–æ‰€æœ‰æ”¯æŒçš„AIæä¾›å•†åˆ—è¡¨
        
        Returns:
            æä¾›å•†åˆ—è¡¨
        """
        return list(self.VISION_MODELS.keys())


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # åˆ›å»ºé…ç½®ç®¡ç†å™¨
    manager = AIConfigManager()
    
    # ç¤ºä¾‹1: ä»å‰ç«¯é…ç½®åŠ è½½
    config_data = {
        'provider': 'openai',
        'model': 'gpt-4-vision-preview',
        'api_key': 'sk-test-key',
        'api_base': 'https://api.openai.com/v1',
        'max_tokens': 2000,
        'temperature': 0.7
    }
    
    try:
        config = manager.load_config_from_frontend(config_data)
        print(f"é…ç½®åŠ è½½æˆåŠŸ: {config}")
        
        # éªŒè¯è§†è§‰æ”¯æŒ
        if manager.validate_vision_support():
            print("âœ… æ¨¡å‹æ”¯æŒè§†è§‰åŠŸèƒ½")
        
        # è·å–å®¢æˆ·ç«¯ï¼ˆéœ€è¦å®‰è£…ç›¸åº”çš„åº“ï¼‰
        # client = manager.get_client()
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
    
    # ç¤ºä¾‹2: æŸ¥è¯¢æ”¯æŒçš„æ¨¡å‹
    print("\næ”¯æŒçš„æä¾›å•†:", manager.get_supported_providers())
    print("OpenAIæ”¯æŒçš„æ¨¡å‹:", manager.get_supported_models('openai'))
    print("Anthropicæ”¯æŒçš„æ¨¡å‹:", manager.get_supported_models('anthropic'))
    print("Googleæ”¯æŒçš„æ¨¡å‹:", manager.get_supported_models('google'))
