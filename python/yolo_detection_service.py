#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLO Detection Service
æä¾›YOLOæ£€æµ‹åŠŸèƒ½å’Œæ¨¡å‹ç®¡ç†API
"""

import os
import base64
import numpy as np
import cv2
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path


class YOLODetectionService:
    """YOLOæ£€æµ‹æœåŠ¡"""
    
    def __init__(self, model_manager=None):
        """
        åˆå§‹åŒ–YOLOæ£€æµ‹æœåŠ¡
        
        Args:
            model_manager: YOLOModelManagerå®ä¾‹
        """
        self.model_manager = model_manager
        self.loaded_models: Dict[str, Any] = {}  # ç¼“å­˜å·²åŠ è½½çš„æ¨¡å‹
        
        print("âœ… YOLOæ£€æµ‹æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
    
    def load_model(self, model_id: str) -> Tuple[bool, str, Optional[Any]]:
        """
        åŠ è½½YOLOæ¨¡å‹
        
        Args:
            model_id: æ¨¡å‹ID
            
        Returns:
            (æ˜¯å¦æˆåŠŸ, æ¶ˆæ¯, æ¨¡å‹å¯¹è±¡)
        """
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½
        if model_id in self.loaded_models:
            return True, "æ¨¡å‹å·²åŠ è½½", self.loaded_models[model_id]
        
        # è·å–æ¨¡å‹è·¯å¾„
        if not self.model_manager:
            return False, "æ¨¡å‹ç®¡ç†å™¨æœªåˆå§‹åŒ–", None
        
        model_path = self.model_manager.get_model_path(model_id)
        if not model_path:
            return False, f"æ¨¡å‹ '{model_id}' ä¸å­˜åœ¨æˆ–æœªä¸‹è½½", None
        
        # åŠ è½½æ¨¡å‹
        try:
            from ultralytics import YOLO
            model = YOLO(model_path)
            self.loaded_models[model_id] = model
            print(f"âœ… æ¨¡å‹ '{model_id}' åŠ è½½æˆåŠŸ")
            return True, "æ¨¡å‹åŠ è½½æˆåŠŸ", model
        except Exception as e:
            return False, f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}", None
    
    def unload_model(self, model_id: str) -> Tuple[bool, str]:
        """
        å¸è½½æ¨¡å‹ä»¥é‡Šæ”¾å†…å­˜
        
        Args:
            model_id: æ¨¡å‹ID
            
        Returns:
            (æ˜¯å¦æˆåŠŸ, æ¶ˆæ¯)
        """
        if model_id in self.loaded_models:
            del self.loaded_models[model_id]
            return True, f"æ¨¡å‹ '{model_id}' å·²å¸è½½"
        return False, "æ¨¡å‹æœªåŠ è½½"
    
    def detect(
        self,
        image: np.ndarray,
        model_id: str = 'yolov8n',
        confidence: float = 0.5,
        iou_threshold: float = 0.45,
        classes: Optional[List[int]] = None,
        draw_results: bool = True
    ) -> Tuple[bool, str, Optional[Dict]]:
        """
        æ‰§è¡ŒYOLOæ£€æµ‹
        
        Args:
            image: è¾“å…¥å›¾åƒï¼ˆBGRæ ¼å¼ï¼‰
            model_id: æ¨¡å‹ID
            confidence: ç½®ä¿¡åº¦é˜ˆå€¼
            iou_threshold: IOUé˜ˆå€¼
            classes: è¦æ£€æµ‹çš„ç±»åˆ«IDåˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæ£€æµ‹æ‰€æœ‰ç±»åˆ«
            draw_results: æ˜¯å¦ç»˜åˆ¶æ£€æµ‹ç»“æœ
            
        Returns:
            (æ˜¯å¦æˆåŠŸ, æ¶ˆæ¯, æ£€æµ‹ç»“æœ)
        """
        # åŠ è½½æ¨¡å‹
        success, msg, model = self.load_model(model_id)
        if not success:
            return False, msg, None
        
        try:
            # è½¬æ¢BGRåˆ°RGBç”¨äºYOLOæ¨ç†
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # æ‰§è¡Œæ£€æµ‹
            results = model(
                image_rgb,
                conf=confidence,
                iou=iou_threshold,
                classes=classes,
                verbose=False
            )
            
            # è§£ææ£€æµ‹ç»“æœ
            detections = []
            annotated_image = image.copy() if draw_results else None
            
            if results and len(results) > 0:
                result = results[0]
                
                if result.boxes is not None and len(result.boxes) > 0:
                    boxes = result.boxes
                    names = result.names
                    
                    for i, box in enumerate(boxes):
                        # è·å–è¾¹ç•Œæ¡†åæ ‡
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
                        
                        # è·å–ç±»åˆ«å’Œç½®ä¿¡åº¦
                        cls_id = int(box.cls[0].cpu().numpy())
                        conf = float(box.conf[0].cpu().numpy())
                        class_name = names[cls_id]
                        
                        # æ·»åŠ åˆ°æ£€æµ‹ç»“æœ
                        detections.append({
                            'bbox': [int(x1), int(y1), int(x2), int(y2)],
                            'class_id': cls_id,
                            'class': class_name,
                            'confidence': conf
                        })
                        
                        # ç»˜åˆ¶æ£€æµ‹æ¡†
                        if draw_results and annotated_image is not None:
                            # ä½¿ç”¨è“è‰²è¾¹ç•Œæ¡†
                            color = (255, 0, 0)  # BGRæ ¼å¼
                            
                            # ç»˜åˆ¶è¾¹ç•Œæ¡†
                            cv2.rectangle(annotated_image, (x1, y1), (x2, y2), color, 2)
                            
                            # å‡†å¤‡æ ‡ç­¾
                            label = f"{class_name}: {conf:.2f}"
                            
                            # è·å–æ–‡æœ¬å¤§å°
                            (text_w, text_h), baseline = cv2.getTextSize(
                                label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
                            )
                            
                            # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
                            cv2.rectangle(
                                annotated_image,
                                (x1, y1 - text_h - 10),
                                (x1 + text_w + 10, y1),
                                color,
                                -1
                            )
                            
                            # ç»˜åˆ¶æ ‡ç­¾æ–‡æœ¬
                            cv2.putText(
                                annotated_image,
                                label,
                                (x1 + 5, y1 - 5),
                                cv2.FONT_HERSHEY_SIMPLEX,
                                0.6,
                                (255, 255, 255),
                                2,
                                cv2.LINE_AA
                            )
            
            # å‡†å¤‡è¿”å›ç»“æœ
            result_data = {
                'detections': detections,
                'count': len(detections),
                'model_id': model_id,
                'confidence_threshold': confidence,
                'iou_threshold': iou_threshold
            }
            
            # å¦‚æœç»˜åˆ¶äº†ç»“æœï¼Œæ·»åŠ æ ‡æ³¨å›¾åƒ
            if draw_results and annotated_image is not None:
                # è½¬æ¢BGRåˆ°RGBç”¨äºå‰ç«¯æ˜¾ç¤º
                annotated_image_rgb = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)
                _, buffer = cv2.imencode('.jpg', annotated_image_rgb, [cv2.IMWRITE_JPEG_QUALITY, 90])
                image_b64 = base64.b64encode(buffer.tobytes()).decode('utf-8')
                result_data['annotated_image'] = f'data:image/jpeg;base64,{image_b64}'
            
            return True, f"æ£€æµ‹å®Œæˆï¼Œå‘ç° {len(detections)} ä¸ªç›®æ ‡", result_data
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            return False, f"æ£€æµ‹å¤±è´¥: {e}", None
    
    def detect_from_base64(
        self,
        image_b64: str,
        model_id: str = 'yolov8n',
        confidence: float = 0.5,
        iou_threshold: float = 0.45,
        classes: Optional[List[int]] = None,
        draw_results: bool = True
    ) -> Tuple[bool, str, Optional[Dict]]:
        """
        ä»base64ç¼–ç çš„å›¾åƒæ‰§è¡Œæ£€æµ‹
        
        Args:
            image_b64: base64ç¼–ç çš„å›¾åƒ
            å…¶ä»–å‚æ•°åŒdetectæ–¹æ³•
            
        Returns:
            (æ˜¯å¦æˆåŠŸ, æ¶ˆæ¯, æ£€æµ‹ç»“æœ)
        """
        try:
            # è§£ç base64å›¾åƒ
            if image_b64.startswith('data:image'):
                image_b64 = image_b64.split(',')[1]
            
            image_bytes = base64.b64decode(image_b64)
            nparr = np.frombuffer(image_bytes, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if image is None:
                return False, "å›¾åƒè§£ç å¤±è´¥", None
            
            # æ‰§è¡Œæ£€æµ‹
            return self.detect(
                image,
                model_id=model_id,
                confidence=confidence,
                iou_threshold=iou_threshold,
                classes=classes,
                draw_results=draw_results
            )
            
        except Exception as e:
            return False, f"å›¾åƒå¤„ç†å¤±è´¥: {e}", None
    
    def get_model_classes(self, model_id: str) -> Tuple[bool, str, Optional[Dict[int, str]]]:
        """
        è·å–æ¨¡å‹çš„ç±»åˆ«ä¿¡æ¯
        
        Args:
            model_id: æ¨¡å‹ID
            
        Returns:
            (æ˜¯å¦æˆåŠŸ, æ¶ˆæ¯, ç±»åˆ«å­—å…¸)
        """
        success, msg, model = self.load_model(model_id)
        if not success:
            return False, msg, None
        
        try:
            classes = model.names
            return True, "è·å–ç±»åˆ«æˆåŠŸ", classes
        except Exception as e:
            return False, f"è·å–ç±»åˆ«å¤±è´¥: {e}", None


# æµ‹è¯•ä»£ç 
if __name__ == '__main__':
    from yolo_model_manager import YOLOModelManager
    
    # åˆå§‹åŒ–ç®¡ç†å™¨å’ŒæœåŠ¡
    manager = YOLOModelManager()
    service = YOLODetectionService(manager)
    
    print("\nğŸ“‹ æµ‹è¯•YOLOæ£€æµ‹æœåŠ¡")
    
    # æµ‹è¯•åŠ è½½æ¨¡å‹
    print("\n1. æµ‹è¯•åŠ è½½æ¨¡å‹...")
    success, msg, model = service.load_model('yolov8n')
    print(f"   {msg}")
    
    if success:
        # æµ‹è¯•è·å–ç±»åˆ«
        print("\n2. æµ‹è¯•è·å–ç±»åˆ«...")
        success, msg, classes = service.get_model_classes('yolov8n')
        if success:
            print(f"   æ¨¡å‹æœ‰ {len(classes)} ä¸ªç±»åˆ«")
            print(f"   å‰5ä¸ªç±»åˆ«: {list(classes.values())[:5]}")
    
    print("\næµ‹è¯•å®Œæˆï¼")
